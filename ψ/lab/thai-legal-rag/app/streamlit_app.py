"""
Thai Legal RAG ‚Äî Streamlit Query Interface

Features:
- Natural language query in Thai
- Automatic fusion retrieval (FAISS + LightRAG)
- Source citations with Drive links
- Chat history per category
- API keys from env only (no UI input)
"""
import sys
from pathlib import Path

import streamlit as st

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.indexing.manager import IndexManager
from src.retrieval.retriever import Retriever
from src.retrieval.reranker import rerank
from src.generation.generator import generate_answer
from src.config import DRIVE_FOLDER_IDS, GEMINI_API_KEYS

st.set_page_config(
    page_title="Thai Legal RAG",
    page_icon="‚öñÔ∏è",
    layout="wide",
)

# --- Sidebar ---
with st.sidebar:
    st.title("‚öñÔ∏è Thai Legal RAG")
    st.caption("‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏à‡∏±‡∏î‡∏ã‡∏∑‡πâ‡∏≠‡∏à‡∏±‡∏î‡∏à‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏Ñ‡∏£‡∏±‡∏ê")

    if not GEMINI_API_KEYS:
        st.error("GEMINI_API_KEYS not set in environment.")
        st.stop()

    category = st.selectbox(
        "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£",
        options=list(DRIVE_FOLDER_IDS.keys()),
        index=0,
    )

    use_lightrag = st.checkbox("‡πÉ‡∏ä‡πâ LightRAG (Graph-based)", value=True)

    with st.expander("‚ÑπÔ∏è ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö"):
        st.markdown("""
        **Thai Legal RAG v2**
        - OCR: Gemini Vision
        - Vector Search: FAISS + LightRAG
        - LLM: Gemini 2.0 Flash
        - Persona: ‡∏ô‡∏¥‡∏ï‡∏¥‡∏Å‡∏£‡∏ä‡∏≥‡∏ô‡∏≤‡∏ç‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©
        """)

# --- Initialize ---
@st.cache_resource
def get_index(use_lightrag_flag: bool) -> tuple:
    index = IndexManager(use_lightrag=use_lightrag_flag)
    retriever = Retriever(index)
    return index, retriever


index, retriever = get_index(use_lightrag)

# --- Chat history ---
chat_key = f"chat_{category}"
if chat_key not in st.session_state:
    st.session_state[chat_key] = []

# --- Main ---
st.header(f"‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢ ‚Äî {category}")

# Display chat history
for msg in st.session_state[chat_key]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if msg.get("sources"):
            with st.expander(f"üìö ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ({len(msg['sources'])} ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£)"):
                for src in msg["sources"]:
                    drive_id = src.get("drive_id", "")
                    name = src.get("name", "Unknown")
                    if drive_id:
                        url = f"https://drive.google.com/file/d/{drive_id}/view"
                        st.markdown(f"- [{name}]({url})")
                    else:
                        st.markdown(f"- {name}")

# Query input
question = st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡πÄ‡∏ä‡πà‡∏ô '‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏°‡∏µ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á'")

if question:
    # Show user message
    st.session_state[chat_key].append({"role": "user", "content": question})
    with st.chat_message("user"):
        st.markdown(question)

    # Retrieve + generate
    with st.chat_message("assistant"):
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
            try:
                raw_results = retriever.retrieve(question, expand=True)
                ranked_chunks = rerank(raw_results)
                result = generate_answer(question, ranked_chunks)

                st.markdown(result["answer"])

                if result["sources"]:
                    with st.expander(f"üìö ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ({len(result['sources'])} ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£)"):
                        for src in result["sources"]:
                            drive_id = src.get("drive_id", "")
                            name = src.get("name", "Unknown")
                            if drive_id:
                                url = f"https://drive.google.com/file/d/{drive_id}/view"
                                st.markdown(f"- [{name}]({url})")
                            else:
                                st.markdown(f"- {name}")

                st.caption(
                    f"Model: {result['model']} | Chunks used: {result['chunks_used']} | "
                    f"FAISS: {len(raw_results.get('faiss', []))} | "
                    f"LightRAG: {len(raw_results.get('lightrag', []))}"
                )

                # Save to history
                st.session_state[chat_key].append({
                    "role": "assistant",
                    "content": result["answer"],
                    "sources": result["sources"],
                })

            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
